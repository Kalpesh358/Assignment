{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12iggoeecAa7",
        "outputId": "baf41473-f24b-48e2-895f-ac8ede646fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original        Porter Stemmer  Lovins Stemmer \n",
            "---------------------------------------------\n",
            "day             day             day            \n",
            "drew            drew            drew           \n",
            "close           close           close          \n",
            "horizon         horizon         horizon        \n",
            "painted         paint           paint          \n",
            "brilliant       brilliant       brilliant      \n",
            "shades          shade           shad           \n",
            "red             red             r              \n",
            "orange          orang           orange         \n",
            "sounds          sound           sound          \n",
            "chirping        chirp           chirp          \n",
            "crickets        cricket         cricket        \n",
            "filled          fill            fill           \n",
            "air             air             air            \n",
            "accompanied     accompani       accompani      \n",
            "gentle          gentl           gentle         \n",
            "rustle          rustl           rustle         \n",
            "leaves          leav            leav           \n",
            "wind            wind            wind           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class LovinsStemmer:\n",
        "    def stem(self, word):\n",
        "        suffixes = ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']\n",
        "        for suffix in suffixes:\n",
        "            if word.endswith(suffix):\n",
        "                return word[:-len(suffix)]\n",
        "        return word\n",
        "\n",
        "# New text for processing\n",
        "text = (\"As the day drew to a close, the horizon was painted with brilliant shades of red and orange. \"\n",
        "        \"The sounds of chirping crickets filled the air, accompanied by the gentle rustle of leaves in the wind.\")\n",
        "\n",
        "# Preprocess the text\n",
        "text = text.lower()\n",
        "text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Initialize stemmers\n",
        "porter_stemmer = PorterStemmer()\n",
        "lovins_stemmer = LovinsStemmer()\n",
        "\n",
        "# Apply stemming\n",
        "porter_stemmed_words = [porter_stemmer.stem(token) for token in filtered_tokens]\n",
        "lovins_stemmed_words = [lovins_stemmer.stem(token) for token in filtered_tokens]\n",
        "\n",
        "# Display results\n",
        "print(\"{:<15} {:<15} {:<15}\".format(\"Original\", \"Porter Stemmer\", \"Lovins Stemmer\"))\n",
        "print(\"-\" * 45)\n",
        "for i in range(len(filtered_tokens)):\n",
        "    print(\"{:<15} {:<15} {:<15}\".format(filtered_tokens[i], porter_stemmed_words[i], lovins_stemmed_words[i]))\n",
        "\n"
      ]
    }
  ]
}